{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Exploration: Depth Images\n",
    "\n",
    "In this notebook, we will learn how to use depth images from the racecar's camera to identify the distance at specific points and find the closest pixel.  We will also explore strategies for handling noise/measurement error.\n",
    "\n",
    "Throughout this notebook, **<font style=\"color:red\">text in bold red</font>** indicates a change you must make to the following code block before running it.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. [Getting Started](#GettingStarted)\n",
    "2. [Taking Depth Photos](#TakingDepthPhotos)\n",
    "3. [Handling Noise](#HandlingNoise)\n",
    "4. [Closest Point](#ClosestPoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"GettingStarted\"></a>\n",
    "## 1. Getting Started\n",
    "\n",
    "**<font style=\"color:red\">If you are running the car in RacecarSim, set `isSimulation` to `True`</font>**. Leave `isSimulation` `False` if you are using a physical car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update isSimulation if necessary\n",
    "isSimulation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will import the necessary libraries for this notebook, including Python libraries (`cv`, `numpy`, etc.) and the Racecar library (`racecar_core`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import statistics\n",
    "from nptyping import NDArray, Shape\n",
    "from typing import Any, Tuple, List, Optional\n",
    "\n",
    "# Import Racecar library\n",
    "import sys\n",
    "sys.path.append(\"../../library\")\n",
    "import racecar_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will help us throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_depth_image(\n",
    "    depth_image: NDArray[Shape[\"*, *\"], np.float32],\n",
    "    max_depth: int = 400,\n",
    "    points: List[Tuple[int, int]] = []\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Displays a color image in the Jupyter Notebook.\n",
    "    \n",
    "    Args:\n",
    "        depth_image: The image to display.\n",
    "        max_depth: The farthest depth to show in the image in cm. Anything past this depth is shown as black.\n",
    "        points: A list of points in (pixel row, pixel column) format to show on the image colored dots.\n",
    "    \"\"\"\n",
    "    # Clip anything above max_depth\n",
    "    np.clip(depth_image, None, max_depth, depth_image)\n",
    "\n",
    "    # Shift down slightly so that 0 (no data) becomes the \"farthest\" color\n",
    "    depth_image = (depth_image - 1) % max_depth\n",
    "\n",
    "    # Convert depth values to colors\n",
    "    color_image = cv.applyColorMap(-cv.convertScaleAbs(depth_image, alpha=255/max_depth), cv.COLORMAP_INFERNO)\n",
    "    \n",
    "    # Draw a dot at each point in points\n",
    "    for point in points:\n",
    "        cv.circle(color_image, (point[1], point[0]), 6, (0, 255, 0), -1)\n",
    "\n",
    "    # Show the image with Matplotlib\n",
    "    plt.imshow(cv.cvtColor(color_image, cv.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def add_noise(\n",
    "    depth_image: NDArray[Shape[\"*, *\"], np.float32],\n",
    "    error_percent = 0.1,\n",
    "    null_percent: float = 0.005\n",
    ") -> NDArray[Shape[\"*, *\"], np.float32]:\n",
    "    \"\"\"\n",
    "    Adds noise to a depth image.\n",
    "    \n",
    "    Args:\n",
    "        depth_image: The original image to which to add noise.\n",
    "        error_percent: The error percentage to introduce to each measurement.\n",
    "        null_percent: The percentage of pixels to set to zero.\n",
    "    \n",
    "    Returns:\n",
    "        A copy of the provided depth_image with noise added.\n",
    "    \"\"\"\n",
    "    # Copy the original image\n",
    "    image = np.copy(depth_image) \n",
    "    \n",
    "    # Apply error_percent to each measurement (gaussian error)\n",
    "    gauss = np.random.normal(1, error_percent, image.shape)\n",
    "    image *= gauss\n",
    "    \n",
    "    # Add null (zero) values\n",
    "    num_nulls = int(image.size * null_percent)\n",
    "    coords = [np.random.randint(0, i - 1, num_nulls) for i in image.shape]\n",
    "    image[tuple(coords)] = 0.0\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def crop(\n",
    "    image: NDArray[(Any, ...), Any],\n",
    "    top_left_inclusive: Tuple[float, float],\n",
    "    bottom_right_exclusive: Tuple[float, float]\n",
    ") -> NDArray[(Any, ...), Any]:\n",
    "    \"\"\"\n",
    "    Crops an image to a rectangle based on the specified pixel points.\n",
    "\n",
    "    Args:\n",
    "        image: The color or depth image to crop.\n",
    "        top_left_inclusive: The (row, column) of the top left pixel of the crop rectangle.\n",
    "        bottom_right_exclusive: The (row, column) of the pixel one past the bottom right corner of the crop rectangle.\n",
    "\n",
    "    Returns:\n",
    "        A cropped version of the image.\n",
    "\n",
    "    Note:\n",
    "        The top_left_inclusive pixel is included in the crop rectangle, but the\n",
    "        bottom_right_exclusive pixel is not.\n",
    "        \n",
    "        If bottom_right_exclusive exceeds the bottom or right edge of the image, the\n",
    "        full image is included along that axis.\n",
    "    \"\"\"\n",
    "    # Extract the minimum and maximum pixel rows and columns from the parameters\n",
    "    r_min, c_min = top_left_inclusive\n",
    "    r_max, c_max = bottom_right_exclusive\n",
    "\n",
    "    # Shorten the array to the specified row and column ranges\n",
    "    return image[r_min:r_max, c_min:c_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a racecar object.  If this step fails, make sure that `isSimulation` has the correct value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Racecar\n",
    "rc = racecar_core.create_racecar(isSimulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TakingDepthPhotos\"></a>\n",
    "## 2. Taking Depth Photos\n",
    "A depth photo is similar to a color photo, except that each pixel stores a distance value rather than color values. In Jupyter Notebook, we can take a depth photo with the car's camera using `rc.camera.get_depth_image_async()`.  Outside of Jupyter Notebook, we must use `rc.camera.get_depth_image()` instead.\n",
    "\n",
    "In order to make sense of the result, we will use `show_depth_image` to convert the distance measurements into colors. For example, the closest measurements are shown as bright yellow, ranging to red to purple to black (out of range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take a depth photo and show a colorized-version\n",
    "image = rc.camera.get_depth_image_async()\n",
    "show_depth_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth images are stored as two-dimensional numpy arrays, using a similar format to color images:\n",
    "\n",
    "* **0th dimension**: pixel rows, indexed from top to bottom.\n",
    "* **1st dimension**: pixel columns, indexed from left to right.\n",
    "\n",
    "Let's inspect the distance at the center of the image. **<span style=\"color:red\">Set `center_row` and `center_col` in the following code block to the center of the image.</span>**  You will likely wish to use `rc.camera.get_height()` and `rc.camera.get_width()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate center row and column\n",
    "center_row = 0\n",
    "center_col = 0\n",
    "\n",
    "# Print the distance of the center pixel\n",
    "center_distance = image[center_row][center_col]\n",
    "print(f\"Distance at pixel {(center_row, center_col)}: {center_distance:.2f} cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"HandlingNoise\"></a>\n",
    "## 3. Handling Noise\n",
    "\n",
    "As you saw in the previous section, we can calculate the distance of an object directly in front of the car by simply accessing the middle element of the depth image.  In practice, however, this approach is not reliable because all sensors have some amount of *noise*, a random variation in measured values.  Furthermore, some pixels may not receive any data, and thus have a *null value* of 0.0 cm.\n",
    "\n",
    "To simulate this, the following code block randomly adds noise and null values to our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noisy_image = add_noise(image)\n",
    "show_depth_image(noisy_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you identify the noise and null values in this image?**\n",
    "\n",
    "To see why this may be a problem, we will measure the center distance ten times with a new noisy version of our original image each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distances = []\n",
    "\n",
    "# Randomize the image and calculate center distance 10 times\n",
    "for i in range (1, 11):\n",
    "    noisy_image = add_noise(image)\n",
    "    center_distance = noisy_image[rc.camera.get_height() // 2][rc.camera.get_width() // 2]\n",
    "    print(f\"Center distance {i}: {center_distance:.2f} cm\")\n",
    "    distances.append(float(center_distance))\n",
    "\n",
    "# Calculate the mean and standard deviation of the center distance measurement\n",
    "print(f\"\\nMean: {statistics.mean(distances):.2f} cm\")\n",
    "print(f\"Standard deviation: {statistics.stdev(distances):.2f} cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the standard deviation across these trials?** To put that in perspective, suppose that we wanted to use the center distance to estimate the speed of the car.  If the car was standing still but the center distance changed by 5 cm per frame, we would estimate that the car was traveling over 3 m/s, more than the top speed of the car!\n",
    "\n",
    "With noise, a single pixel is not a reliable measurement of distance.  Instead, we should factor in neighboring pixels to mitigate the effect of error/noise. One way to do this is by applying a [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) to the original image.  Each pixel is updated with a weighted average of its neighbors, with greater weight given to closer neighbors.  The *kernel size* determines how large of an area to include in this average.\n",
    "\n",
    "In the following code block, we use the OpenCV function [GaussianBlur](https://docs.opencv.org/4.3.0/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1) to apply Gaussian blur to our depth image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel size must be odd\n",
    "kernel_size = 11\n",
    "blurred_image = cv.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "show_depth_image(blurred_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: If your image contained areas that were out of range, you may notice a sharp outline appearing along the boundary of these regions.  This occurs because out of range pixels are represented as 0.0, so when averaged with surrounding areas, they cause the average to *decrease*.  This causes pixel near out-of-range regions to appear *closer* after blurring. \n",
    "\n",
    "Run the following code block and use the slider to experiment with different kernel sizes.  **As kernel size increases, does the image become more or less blurred? Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_image(depth_image, kernel_size):\n",
    "    # Blur and show image\n",
    "    blurred_image = cv.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "    show_depth_image(blurred_image)\n",
    "    \n",
    "widgets.interact(blur_image, \n",
    "                 depth_image=widgets.fixed(image),\n",
    "                 kernel_size=widgets.IntSlider(1, 1, 61, 2, continuous_update = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each individual pixel in the blurred image is an average of many pixels from the original image.  This helps compensate for noise and null values.\n",
    "\n",
    "You now have all of the tools necessary to write a more robust center distance algorithm.  **<span style=\"color:red\">Finish writing `get_depth_image_center_distance` in the following code block.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_image_center_distance(\n",
    "    depth_image: NDArray[Shape[\"*, *\"], np.float32], \n",
    "    kernel_size: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Finds the distance of a pixel averaged with its neighbors in a depth image.\n",
    "\n",
    "    Args:\n",
    "        depth_image: The depth image to process.\n",
    "        pix_coord: The (row, column) of the pixel to measure.\n",
    "        kernel_size: The size of the area to average around the pixel.\n",
    "\n",
    "    Returns:\n",
    "        The distance in cm of the object at the provided pixel.\n",
    "\n",
    "    Warning:\n",
    "        kernel_size must be positive and odd.\n",
    "\n",
    "    Note:\n",
    "        The larger the kernel_size, the more that the requested pixel is averaged\n",
    "        with the distances of the surrounding pixels.  This helps reduce noise at the\n",
    "        cost of reduced accuracy.\n",
    "    \"\"\"\n",
    "    # TODO: apply a gaussian blur to the image\n",
    "\n",
    "    \n",
    "    # TODO: find and return the center distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the same test as before using our `get_depth_image_center_distance` function.  Once again, we will randomly add noise to the original image and measure the center distance ten times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_size = 11\n",
    "distances = []\n",
    "\n",
    "# Randomize the image and calculate center distance 10 times\n",
    "for i in range (1, 11):\n",
    "    noisy_image = add_noise(image)\n",
    "    center_distance = get_depth_image_center_distance(noisy_image, kernel_size)\n",
    "    print(f\"Center distance {i}: {center_distance:.2f} cm\")\n",
    "    distances.append(float(center_distance))\n",
    "\n",
    "# Calculate the mean and standard deviation of the center distance measurement\n",
    "print(f\"\\nMean: {statistics.mean(distances):.2f} cm\")\n",
    "print(f\"Standard deviation: {statistics.stdev(distances):.2f} cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these results to our original test without blurring.  **Has the standard deviation decreased?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ClosestPoint\"></a>\n",
    "## 4. Closest Point\n",
    "\n",
    "We can also use depth images to find the closest point, which is useful for identifying and reacting to nearby objects. Once again, we should apply a Gaussian blur to minimize the impact of noise.\n",
    "\n",
    "However, a problem will arise if any part of the depth image is out of range, as it will have a depth value of 0.0.  To fix this, we can shift down each value by a small amount (such as 0.01 cm) and then mod by a large number (such as 10,000 cm).  This way, 0.0 becomes -0.01, which after modding becomes 9,999.99 cm, a very large distance that will not interfere with the true minimum.\n",
    "\n",
    "**<span style=\"color:red\">Finish writing `get_closest_pixel` to find the row and column of the closest pixel in a depth image.</span>**.  You will likely wish to use the OpenCV function [minMaxLoc](https://docs.opencv.org/4.3.0/d2/de8/group__core__array.html#gab473bf2eb6d14ff97e89b355dac20707).  Note that the positions returned by ``minMaxLoc`` are in (column, row) format, while `get_closest_pixel` should return in (row, column) format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_pixel(\n",
    "    depth_image: NDArray[Shape[\"*, *\"], np.float32],\n",
    "    kernel_size: int = 5\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Finds the closest pixel in a depth image.\n",
    "\n",
    "    Args:\n",
    "        depth_image: The depth image to process.\n",
    "        kernel_size: The size of the area to average around each pixel.\n",
    "\n",
    "    Returns:\n",
    "        The (row, column) of the pixel which is closest to the car.\n",
    "\n",
    "    Warning:\n",
    "        kernel_size be positive and odd.\n",
    "        It is highly recommended that you crop off the bottom of the image, or else\n",
    "        this function will likely return the ground directly in front of the car.\n",
    "\n",
    "    Note:\n",
    "        The larger the kernel_size, the more that the depth of each pixel is averaged\n",
    "        with the distances of the surrounding pixels.  This helps reduce noise at the\n",
    "        cost of reduced accuracy.\n",
    "    \"\"\"\n",
    "    # Shift 0.0 values to 10,000 so they are not considered for the closest pixel\n",
    "    depth_image = (depth_image - 0.01) % 10000\n",
    "    \n",
    "    # TODO: Apply a gaussian blur using kernel_size\n",
    "\n",
    "    \n",
    "    # TODO: Find the pixel location of the minimum depth and return it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `get_closest_pixel` to draw a green dot at the location of the closest pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_pixel = get_closest_pixel(image)\n",
    "show_depth_image(image, points=[closest_pixel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless something is directly in front of the camera, the closest point was likely the ground in front of the car.  This is not a particularly useful result, so we should first crop off the bottom of the image.\n",
    "\n",
    "Right now, `top_left_inclusive` and `bottom_right_exclusive` contain (row, column) pairs which include the entire image. **<span style=\"color:red\">Update `top_left_inclusive` and `bottom_right_exclusive` to crop off the bottom third of the image before running `get_depth_image_center_distance`.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change top_left_inclusive and/or bottom_right_exclusive to crop off the bottom third of the image\n",
    "top_left_inclusive = (0, 0)\n",
    "bottom_right_exclusive = (rc.camera.get_height(), rc.camera.get_width())\n",
    "\n",
    "cropped_image = crop(image, top_left_inclusive, bottom_right_exclusive)\n",
    "closest_pixel = get_closest_pixel(cropped_image)\n",
    "show_depth_image(cropped_image, points=[closest_pixel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image should now show a more meaningful closest point.  If necessary, you may need to experiment with different crop windows or move the car and take a new depth image.\n",
    "\n",
    "You are now ready to begin using the depth camera to implement a \"safety stop\" feature in `lab3a.py`.  Good luck, and don't be afraid to ask questions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
